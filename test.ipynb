{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been saved to Lunyu_Corpus.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'Lunyu Complete Analysis.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Initialize an empty list to store the corpus data\n",
    "corpus_data = []\n",
    "\n",
    "# Define the number of rows in a set\n",
    "rows_per_set = 6\n",
    "\n",
    "# Loop through the CSV file in steps of rows_per_set to process each set\n",
    "for start_index in range(0, len(df), rows_per_set):\n",
    "    # Check if the set is complete\n",
    "    if start_index + rows_per_set > len(df):\n",
    "        break\n",
    "    \n",
    "    # Extract the data for one set\n",
    "    id_value = str(df.iloc[start_index, 0])\n",
    "    meaning_value = str(df.iloc[start_index + 4, 0]) if pd.notna(df.iloc[start_index + 4, 0]) else \"\"\n",
    "    \n",
    "    # Extract the text details\n",
    "    text_data = []\n",
    "    for col_index in range(1, df.shape[1]):\n",
    "        if pd.notna(df.iloc[start_index + 1, col_index]):\n",
    "            text_data.append({\n",
    "                \"unicode\": str(df.iloc[start_index, col_index]),\n",
    "                \"character\": str(df.iloc[start_index + 1, col_index]),\n",
    "                \"pronunciation\": str(df.iloc[start_index + 2, col_index]),\n",
    "                \"chinese\": str(df.iloc[start_index + 3, col_index])\n",
    "            })\n",
    "\n",
    "    # Append the extracted set to the corpus data list\n",
    "    corpus_data.append({\n",
    "        \"id\": id_value,\n",
    "        \"metadata\": {\n",
    "            \"meaning\": meaning_value\n",
    "        },\n",
    "        \"text\": text_data\n",
    "    })\n",
    "\n",
    "# Convert the corpus data to JSON format\n",
    "json_output = {\n",
    "    \"corpus_data\": corpus_data\n",
    "}\n",
    "\n",
    "# Save the JSON data to a file\n",
    "output_path = 'Lunyu_Corpus.json'\n",
    "with open(output_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(json_output, json_file, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"JSON data has been saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'Lunyu Complete Analysis.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Initialize an empty DataFrame to store the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Define the number of rows in a set\n",
    "rows_per_set = 6\n",
    "\n",
    "# Process each set\n",
    "for start_index in range(0, len(df), rows_per_set):\n",
    "    # Check if the set is complete\n",
    "    if start_index + rows_per_set > len(df):\n",
    "        break\n",
    "    \n",
    "    # Combine the rows by concatenating them horizontally\n",
    "    combined_row = pd.concat([df.iloc[start_index + i] for i in range(rows_per_set)], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # Append the combined row to the DataFrame\n",
    "    combined_df = pd.concat([combined_df, combined_row.to_frame().T], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV data has been saved to Combined_Lunyu.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the combined DataFrame to a new CSV file\n",
    "output_combined_csv_path = 'Combined_Lunyu.csv'\n",
    "combined_df.to_csv(output_combined_csv_path, index=False)\n",
    "\n",
    "print(f\"Combined CSV data has been saved to {output_combined_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0       1     2    3    4     5     6       7      8    \\\n",
      "0               0316b1Â      NaN   NaN  NaN  NaN   NaN   NaN     NaN    NaN   \n",
      "1                   NaN     NaN   NaN  NaN  NaN   NaN   NaN     NaN    NaN   \n",
      "2  ä¸ç‚ºéçŸ£ã€‚è“‹æœ‰æ–‡å­ä¹‹è³ªï¼Œå†æ–¯å¯çŸ£ã€‚ç„¡æ–‡å­     NaN   NaN  NaN  NaN   NaN   NaN     NaN    NaN   \n",
      "3                     å¦‚       è³ª    ç„¡ã€‚    ä¸‰    æ€     é    å‰‡ï¼›       ä¸     å¯ã€‚   \n",
      "4                  ljÉ¨1  lhjwÉ¨2  Å‹wu2  ká»¥2  ku1  mji1  Åºwe1  nioow1  Åºier1   \n",
      "\n",
      "    9    ...   98     99    100   101     102  103   104    105  106  107  \n",
      "0   NaN  ...   NaN    NaN   NaN   NaN     NaN  NaN   NaN    NaN  NaN  NaN  \n",
      "1   NaN  ...     è³ª     æœ‰ã€‚     å†    å‰‡ï¼›       å¯   ä¹Ÿã€‚   [æ–‡]    [å­]  NaN  NaN  \n",
      "2   NaN  ...  lew1  goor1   no2   sá»1  sjiij2  do2   ku1  ljÉ¨É¨1  NaN  NaN  \n",
      "3   å­”ã€€å­  ...     ğ—–£      ğ˜ƒ     ğ˜     ğ˜“       ğ—–µ    ğ˜˜     ğ˜ƒ¡      ğ—¡¶  NaN  NaN  \n",
      "4  ljÉ¨1  ...  4925   4612  3433  3849    4859  197  4310   1718  NaN  NaN  \n",
      "\n",
      "[5 rows x 108 columns]\n",
      "Combined CSV data has been saved to 2Combined_Lunyu.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'Lunyu Complete Analysis.csv'\n",
    "df = pd.read_csv(file_path, header=None)  # No header, as each row is part of a set\n",
    "\n",
    "# Initialize an empty list to store combined rows\n",
    "combined_data = []\n",
    "\n",
    "# Define the number of rows in a set\n",
    "rows_per_set = 6\n",
    "\n",
    "# Process each set\n",
    "for start_index in range(0, len(df), rows_per_set):\n",
    "    # Check if the set is complete\n",
    "    if start_index + rows_per_set > len(df):\n",
    "        break\n",
    "    \n",
    "    # Extract and combine the 6 rows into a single row\n",
    "    combined_row = []\n",
    "    for i in range(rows_per_set):\n",
    "        combined_row.extend(df.iloc[start_index + i].tolist())\n",
    "    \n",
    "    # Append the combined row to the list\n",
    "    combined_data.append(combined_row)\n",
    "\n",
    "# Create a DataFrame from the combined data\n",
    "combined_df = pd.DataFrame(combined_data)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(combined_df.head())\n",
    "\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "output_combined_csv_path = '2Combined_Lunyu.csv'\n",
    "combined_df.to_csv(output_combined_csv_path, index=False, header=False)\n",
    "\n",
    "print(f\"Combined CSV data has been saved to {output_combined_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0316b1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>è³ª</td>\n",
       "      <td>æœ‰ã€‚</td>\n",
       "      <td>å†</td>\n",
       "      <td>å‰‡ï¼›</td>\n",
       "      <td>å¯</td>\n",
       "      <td>ä¹Ÿã€‚</td>\n",
       "      <td>[æ–‡]</td>\n",
       "      <td>[å­]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ä¸ç‚ºéçŸ£ã€‚è“‹æœ‰æ–‡å­ä¹‹è³ªï¼Œå†æ–¯å¯çŸ£ã€‚ç„¡æ–‡å­</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>lew1</td>\n",
       "      <td>goor1</td>\n",
       "      <td>no2</td>\n",
       "      <td>sá»1</td>\n",
       "      <td>sjiij2</td>\n",
       "      <td>do2</td>\n",
       "      <td>ku1</td>\n",
       "      <td>ljÉ¨É¨1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>å¦‚</td>\n",
       "      <td>è³ª</td>\n",
       "      <td>ç„¡ã€‚</td>\n",
       "      <td>ä¸‰</td>\n",
       "      <td>æ€</td>\n",
       "      <td>é</td>\n",
       "      <td>å‰‡ï¼›</td>\n",
       "      <td>ä¸</td>\n",
       "      <td>å¯ã€‚</td>\n",
       "      <td>å­”ã€€å­</td>\n",
       "      <td>...</td>\n",
       "      <td>ğ—–£</td>\n",
       "      <td>ğ˜ƒ</td>\n",
       "      <td>ğ˜</td>\n",
       "      <td>ğ˜“</td>\n",
       "      <td>ğ—–µ</td>\n",
       "      <td>ğ˜˜</td>\n",
       "      <td>ğ˜ƒ¡</td>\n",
       "      <td>ğ—¡¶</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ljÉ¨1</td>\n",
       "      <td>lhjwÉ¨2</td>\n",
       "      <td>Å‹wu2</td>\n",
       "      <td>ká»¥2</td>\n",
       "      <td>ku1</td>\n",
       "      <td>mji1</td>\n",
       "      <td>Åºwe1</td>\n",
       "      <td>nioow1</td>\n",
       "      <td>Åºier1</td>\n",
       "      <td>ljÉ¨1</td>\n",
       "      <td>...</td>\n",
       "      <td>4925</td>\n",
       "      <td>4612</td>\n",
       "      <td>3433</td>\n",
       "      <td>3849</td>\n",
       "      <td>4859</td>\n",
       "      <td>197</td>\n",
       "      <td>4310</td>\n",
       "      <td>1718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>NaN</td>\n",
       "      <td>äºº</td>\n",
       "      <td>å›</td>\n",
       "      <td>å¤©</td>\n",
       "      <td>æ–¼</td>\n",
       "      <td>å‰‡ï¼›</td>\n",
       "      <td>çŒ¶</td>\n",
       "      <td>{å­</td>\n",
       "      <td>çˆ¶</td>\n",
       "      <td>ä¹‹æ–¼}</td>\n",
       "      <td>...</td>\n",
       "      <td>ğ—–µ</td>\n",
       "      <td>ğ˜ª</td>\n",
       "      <td>ğ—Œ­</td>\n",
       "      <td>ğ˜“º</td>\n",
       "      <td>ğ—‚¸</td>\n",
       "      <td>ğ˜˜¥</td>\n",
       "      <td>ğ˜•‹</td>\n",
       "      <td>ğ˜‚¬</td>\n",
       "      <td>ğ—†ª</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>NaN</td>\n",
       "      <td>bju1</td>\n",
       "      <td>tshjiij1</td>\n",
       "      <td>ku1</td>\n",
       "      <td>mÉ™1</td>\n",
       "      <td>zjÉ¨Ì£1</td>\n",
       "      <td>Â·jÉ¨2</td>\n",
       "      <td>wo2</td>\n",
       "      <td>bju1</td>\n",
       "      <td>tshjiij1</td>\n",
       "      <td>...</td>\n",
       "      <td>460</td>\n",
       "      <td>1553</td>\n",
       "      <td>1491</td>\n",
       "      <td>3125</td>\n",
       "      <td>3612</td>\n",
       "      <td>1824</td>\n",
       "      <td>972</td>\n",
       "      <td>4853</td>\n",
       "      <td>2778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ğ˜–‘</td>\n",
       "      <td>ğ˜œ•</td>\n",
       "      <td>ğ—…‹</td>\n",
       "      <td>ğ—¹‘</td>\n",
       "      <td>ğ˜–‘</td>\n",
       "      <td>ğ˜œ•</td>\n",
       "      <td>ğ˜Ÿ‚</td>\n",
       "      <td>ğ˜“º</td>\n",
       "      <td>ğ—‚¸</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3510</td>\n",
       "      <td>4979</td>\n",
       "      <td>3687</td>\n",
       "      <td>4391</td>\n",
       "      <td>1824</td>\n",
       "      <td>2386</td>\n",
       "      <td>4329</td>\n",
       "      <td>5615</td>\n",
       "      <td>1348</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>1017a8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>435 rows Ã— 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0       1         2     3     4      5     6       7    \\\n",
       "0                 0316b1Â      NaN       NaN   NaN   NaN    NaN   NaN     NaN   \n",
       "1                     NaN     NaN       NaN   NaN   NaN    NaN   NaN     NaN   \n",
       "2    ä¸ç‚ºéçŸ£ã€‚è“‹æœ‰æ–‡å­ä¹‹è³ªï¼Œå†æ–¯å¯çŸ£ã€‚ç„¡æ–‡å­     NaN       NaN   NaN   NaN    NaN   NaN     NaN   \n",
       "3                       å¦‚       è³ª        ç„¡ã€‚     ä¸‰     æ€      é    å‰‡ï¼›       ä¸   \n",
       "4                    ljÉ¨1  lhjwÉ¨2      Å‹wu2   ká»¥2   ku1   mji1  Åºwe1  nioow1   \n",
       "..                    ...     ...       ...   ...   ...    ...   ...     ...   \n",
       "430                   NaN       äºº         å›     å¤©     æ–¼     å‰‡ï¼›     çŒ¶      {å­   \n",
       "431                   NaN    bju1  tshjiij1   ku1   mÉ™1  zjÉ¨Ì£1  Â·jÉ¨2     wo2   \n",
       "432                   NaN       ğ˜–‘         ğ˜œ•     ğ—…‹     ğ—¹‘      ğ˜–‘     ğ˜œ•       ğ˜Ÿ‚   \n",
       "433                   NaN    3510      4979  3687  4391   1824  2386    4329   \n",
       "434                1017a8     NaN       NaN   NaN   NaN    NaN   NaN     NaN   \n",
       "\n",
       "       8         9    ...   98     99    100   101     102   103   104    105  \\\n",
       "0      NaN       NaN  ...   NaN    NaN   NaN   NaN     NaN   NaN   NaN    NaN   \n",
       "1      NaN       NaN  ...     è³ª     æœ‰ã€‚     å†    å‰‡ï¼›       å¯    ä¹Ÿã€‚   [æ–‡]    [å­]   \n",
       "2      NaN       NaN  ...  lew1  goor1   no2   sá»1  sjiij2   do2   ku1  ljÉ¨É¨1   \n",
       "3       å¯ã€‚       å­”ã€€å­  ...     ğ—–£      ğ˜ƒ     ğ˜     ğ˜“       ğ—–µ     ğ˜˜     ğ˜ƒ¡      ğ—¡¶   \n",
       "4    Åºier1      ljÉ¨1  ...  4925   4612  3433  3849    4859   197  4310   1718   \n",
       "..     ...       ...  ...   ...    ...   ...   ...     ...   ...   ...    ...   \n",
       "430      çˆ¶       ä¹‹æ–¼}  ...     ğ—–µ      ğ˜ª     ğ—Œ­     ğ˜“º       ğ—‚¸     ğ˜˜¥     ğ˜•‹      ğ˜‚¬   \n",
       "431   bju1  tshjiij1  ...   460   1553  1491  3125    3612  1824   972   4853   \n",
       "432      ğ˜“º         ğ—‚¸  ...   NaN    NaN   NaN   NaN     NaN   NaN   NaN    NaN   \n",
       "433   5615      1348  ...   NaN    NaN   NaN   NaN     NaN   NaN   NaN    NaN   \n",
       "434    NaN       NaN  ...   NaN    NaN   NaN   NaN     NaN   NaN   NaN    NaN   \n",
       "\n",
       "      106  107  \n",
       "0     NaN  NaN  \n",
       "1     NaN  NaN  \n",
       "2     NaN  NaN  \n",
       "3     NaN  NaN  \n",
       "4     NaN  NaN  \n",
       "..    ...  ...  \n",
       "430     ğ—†ª  NaN  \n",
       "431  2778  NaN  \n",
       "432   NaN  NaN  \n",
       "433   NaN  NaN  \n",
       "434   NaN  NaN  \n",
       "\n",
       "[435 rows x 108 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed CSV saved to output2.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def transform_csv(input_file, output_file):\n",
    "    with open(input_file, newline='', encoding='utf-8') as infile, open(output_file, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        reader = csv.reader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "\n",
    "        # åˆæœŸåŒ–\n",
    "        combined_rows = [[] for _ in range(6)]\n",
    "        row_index = 0\n",
    "        \n",
    "        for row in reader:\n",
    "            if not any(row):  # ç©ºè¡Œã®æ¤œå‡º\n",
    "                row_index = 0\n",
    "                continue\n",
    "            \n",
    "            combined_rows[row_index].extend(row)\n",
    "            row_index += 1\n",
    "            \n",
    "            # å„ã‚»ãƒƒãƒˆã¯6è¡Œã§1ã‚»ãƒƒãƒˆãªã®ã§ã€6è¡Œç›®ã®å¾Œã¯æ¬¡ã®ã‚»ãƒƒãƒˆã«ç§»ã‚‹\n",
    "            if row_index == 6:\n",
    "                row_index = 0\n",
    "\n",
    "        # å¤‰æ›ã—ãŸè¡Œã‚’æ›¸ãå‡ºã™\n",
    "        for row in combined_rows:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# ä½¿ç”¨ä¾‹\n",
    "input_file = 'Lunyu Complete Analysis.csv'\n",
    "output_file = 'output2.csv'\n",
    "transform_csv(input_file, output_file)\n",
    "\n",
    "print(f\"Transformed CSV saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed JSON saved to output.json\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(input_file, output_file):\n",
    "    with open(input_file, newline='', encoding='utf-8') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        rows = list(reader)\n",
    "    \n",
    "    # JSONãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹ãƒªã‚¹ãƒˆ\n",
    "    corpus_data = []\n",
    "    \n",
    "    # å„ã‚»ãƒƒãƒˆï¼ˆ6è¡Œãšã¤ï¼‰ã‚’å‡¦ç†\n",
    "    num_sets = len(rows[0]) // 4  # å„ã‚»ãƒƒãƒˆãŒ4åˆ—ï¼ˆid, meaning, text, pronunciationï¼‰ã§æ§‹æˆã•ã‚Œã‚‹ã¨ä»®å®š\n",
    "    \n",
    "    for i in range(num_sets):\n",
    "        # idåˆ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n",
    "        idx = i * 4\n",
    "        \n",
    "        corpus_entry = {\n",
    "            \"id\": rows[0][idx],\n",
    "            \"metadata\": {\n",
    "                \"meaning\": rows[5][idx]  # æœ€å¾Œã®è¡ŒãŒmeaning\n",
    "            },\n",
    "            \"text\": []\n",
    "        }\n",
    "        \n",
    "        for j in range(4):\n",
    "            text_entry = {\n",
    "                \"unicode\": rows[1][idx + j],\n",
    "                \"character\": rows[2][idx + j],\n",
    "                \"pronunciation\": rows[3][idx + j],\n",
    "                \"chinese\": rows[4][idx + j]\n",
    "            }\n",
    "            corpus_entry[\"text\"].append(text_entry)\n",
    "        \n",
    "        corpus_data.append(corpus_entry)\n",
    "    \n",
    "    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump({\"corpus_data\": corpus_data}, outfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "# ä½¿ç”¨ä¾‹\n",
    "input_file = 'test_row_data.csv'\n",
    "output_file = 'output.json'\n",
    "csv_to_json(input_file, output_file)\n",
    "\n",
    "print(f\"Transformed JSON saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed JSON saved to output3.json\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(input_file, output_file):\n",
    "    with open(input_file, newline='', encoding='utf-8') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        rows = list(reader)\n",
    "    \n",
    "    # JSONãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹ãƒªã‚¹ãƒˆ\n",
    "    corpus_data = []\n",
    "    \n",
    "    # ç¾åœ¨å‡¦ç†ä¸­ã®ã‚»ãƒƒãƒˆã‚’ä¿æŒã™ã‚‹å¤‰æ•°\n",
    "    current_set = {}\n",
    "    text_entries = []\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        if not any(row):  # ç©ºè¡Œã®æ¤œå‡º\n",
    "            if current_set:  # æ—¢å­˜ã®ã‚»ãƒƒãƒˆãŒã‚ã‚‹å ´åˆ\n",
    "                current_set[\"text\"] = text_entries\n",
    "                corpus_data.append(current_set)\n",
    "                current_set = {}\n",
    "                text_entries = []\n",
    "            continue\n",
    "        \n",
    "        # è¡Œã®ç•ªå·ã«åŸºã¥ã„ã¦ã‚»ãƒƒãƒˆã‚’ä½œæˆ\n",
    "        if i % 7 == 0:\n",
    "            current_set[\"id\"] = row[0]\n",
    "        elif i % 7 == 1:\n",
    "            unicode_list = row\n",
    "        elif i % 7 == 2:\n",
    "            character_list = row\n",
    "        elif i % 7 == 3:\n",
    "            pronunciation_list = row\n",
    "        elif i % 7 == 4:\n",
    "            chinese_list = row\n",
    "        elif i % 7 == 5:\n",
    "            current_set[\"metadata\"] = {\"meaning\": row[0]}\n",
    "            # å„ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’ä½œæˆ\n",
    "            for u, c, p, ch in zip(unicode_list, character_list, pronunciation_list, chinese_list):\n",
    "                text_entries.append({\n",
    "                    \"unicode\": u,\n",
    "                    \"character\": c,\n",
    "                    \"pronunciation\": p,\n",
    "                    \"chinese\": ch\n",
    "                })\n",
    "    \n",
    "    # æœ€å¾Œã®ã‚»ãƒƒãƒˆã‚’è¿½åŠ \n",
    "    if current_set:\n",
    "        current_set[\"text\"] = text_entries\n",
    "        corpus_data.append(current_set)\n",
    "    \n",
    "    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump({\"corpus_data\": corpus_data}, outfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "# ä½¿ç”¨ä¾‹\n",
    "input_file = 'Lunyu Complete Analysis.csv'\n",
    "output_file = 'output3.json'\n",
    "csv_to_json(input_file, output_file)\n",
    "\n",
    "print(f\"Transformed JSON saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed JSON saved to output4.json\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(input_file, output_file):\n",
    "    with open(input_file, newline='', encoding='utf-8') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        rows = list(reader)\n",
    "    \n",
    "    corpus_data = []  # JSONãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã™ã‚‹ãƒªã‚¹ãƒˆ\n",
    "    \n",
    "    current_set = {}  # ç¾åœ¨å‡¦ç†ä¸­ã®ã‚»ãƒƒãƒˆã‚’ä¿æŒã™ã‚‹å¤‰æ•°\n",
    "    text_entries = []  # ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒ³ãƒˆãƒªã‚’ä¿æŒã™ã‚‹ãƒªã‚¹ãƒˆ\n",
    "\n",
    "    for i, row in enumerate(rows):\n",
    "        if not any(row):  # ç©ºè¡Œã®æ¤œå‡º\n",
    "            if current_set:  # æ—¢å­˜ã®ã‚»ãƒƒãƒˆãŒã‚ã‚‹å ´åˆ\n",
    "                # ç©ºã®ã‚¨ãƒ³ãƒˆãƒªã‚’é™¤å¤–\n",
    "                current_set[\"text\"] = [entry for entry in text_entries if any(entry.values())]\n",
    "                corpus_data.append(current_set)\n",
    "                current_set = {}\n",
    "                text_entries = []\n",
    "            continue\n",
    "        \n",
    "        if i % 7 == 0:\n",
    "            current_set[\"id\"] = row[0]\n",
    "        elif i % 7 == 1:\n",
    "            unicode_list = row\n",
    "        elif i % 7 == 2:\n",
    "            character_list = row\n",
    "        elif i % 7 == 3:\n",
    "            pronunciation_list = row\n",
    "        elif i % 7 == 4:\n",
    "            chinese_list = row\n",
    "        elif i % 7 == 5:\n",
    "            current_set[\"metadata\"] = {\"meaning\": row[0]}\n",
    "            for u, c, p, ch in zip(unicode_list, character_list, pronunciation_list, chinese_list):\n",
    "                entry = {\n",
    "                    \"unicode\": u,\n",
    "                    \"character\": c,\n",
    "                    \"pronunciation\": p,\n",
    "                    \"chinese\": ch\n",
    "                }\n",
    "                text_entries.append(entry)\n",
    "    \n",
    "    if current_set:  # æœ€å¾Œã®ã‚»ãƒƒãƒˆã‚’è¿½åŠ \n",
    "        current_set[\"text\"] = [entry for entry in text_entries if any(entry.values())]\n",
    "        corpus_data.append(current_set)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump({\"corpus_data\": corpus_data}, outfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "# ä½¿ç”¨ä¾‹\n",
    "input_file = 'Lunyu Complete Analysis.csv'\n",
    "output_file = 'output4.json'\n",
    "csv_to_json(input_file, output_file)\n",
    "\n",
    "print(f\"Transformed JSON saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
